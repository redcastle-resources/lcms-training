{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2eb2fc88-25b8-4d5a-8a2c-b8e40cbe6178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae243bdf-1298-4668-a561-3709d7a26995",
   "metadata": {
    "id": "title:generic,gcp"
   },
   "source": [
    "<img width=50px  src = 'https://apps.fs.usda.gov/lcms-viewer/images/lcms-icon.png'>\n",
    "\n",
    "# LCMS Map Validation\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/redcastle-resources/lcms-training/blob/main/7-Map_Validation.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/redcastle-resources/lcms-training/blob/main/7-Map_Validation.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://github.com/redcastle-resources/lcms-training/blob/main/7-Map_Validation.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4603c77e-11e2-45bc-9ddd-b75c4a170d8b",
   "metadata": {
    "id": "overview:mlops"
   },
   "source": [
    "\n",
    "## Overview\n",
    "\n",
    "\n",
    "This notebook teaches how to assess map accuracy of LCMS outputs\n",
    "\n",
    "### Objective\n",
    "\n",
    "In this tutorial, you learn how to assess the map accuracy of LCMS map outputs\n",
    "\n",
    "This tutorial uses the following Google Cloud services:\n",
    "\n",
    "- `Google Earth Engine`\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "- Understanding the difference between model and map accuracy\n",
    "- Simulating map accuracy with k fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4fae6857-1dfc-448b-b92f-85ec010f8460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Module imports\n",
    "#!python -m pip install geeViz --upgrade\n",
    "try:\n",
    "    import geeViz.getImagesLib as getImagesLib\n",
    "except:\n",
    "    !python -m pip install geeViz\n",
    "    import geeViz.getImagesLib as getImagesLib\n",
    "\n",
    "import geeViz.changeDetectionLib as changeDetectionLib\n",
    "import geeViz.assetManagerLib as aml\n",
    "import geeViz.taskManagerLib as tml\n",
    "import geeViz.gee2Pandas as g2p\n",
    "import inspect,operator,os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd  \n",
    "\n",
    "\n",
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import GroupKFold\n",
    "    from sklearn.metrics import accuracy_score,classification_report,balanced_accuracy_score,cohen_kappa_score\n",
    "    from sklearn import metrics \n",
    "except:\n",
    "    !pip install -U scikit-learn\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import GroupKFold\n",
    "    from sklearn.metrics import accuracy_score,classification_report,balanced_accuracy_score,cohen_kappa_score\n",
    "    from sklearn import metrics \n",
    "# from IPython.display import IFrame,display, HTML\n",
    "ee = getImagesLib.ee\n",
    "Map = getImagesLib.Map\n",
    "\n",
    "# Can set the port used for viewing map outputs\n",
    "Map.port = 1235\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4a573f-29c3-483d-9e35-f96910089b67",
   "metadata": {},
   "source": [
    "## Before you begin\n",
    "\n",
    "### Set your current URL under `workbench_url`\n",
    "* This will be in your URL/search bar at the top of the browser window you are currently in\n",
    "* It will look something like `https://1234567890122-dot-us-west3.notebooks.googleusercontent.com/`\n",
    "\n",
    "### Set a folder to use for all exports under `export_path_root` \n",
    "* It will be something like `projects/projectID/assets/someFolder`\n",
    "* This folder does not have to already exist. If it does not exist, it will be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdb3a04b-c869-411d-a552-d624575ffcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "workbench_url = 'https://53c21733d8125e22-dot-us-west3.notebooks.googleusercontent.com'\n",
    "export_path_root  = 'projects/rcr-gee/assets/lcms-training'\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ed03b3ae-31ec-4caf-9add-5d9d1eb1bec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Bring in all folders/collections that are needed\n",
    "# These must already exist as they are created in previous notebooks\n",
    "\n",
    "export_timeSync_folder = f'{export_path_root}/lcms-training_module-4_timeSync'\n",
    "\n",
    "export_assembledLCMSOutputs_collection = f'{export_path_root}/lcms-training_module-6_assembledLCMSOutputs'\n",
    "\n",
    "# This is the pre-made TimeSync data\n",
    "# Creating this dataset is not covered in this set of notebooks\n",
    "timeSync_featureCollection = 'projects/lcms-292214/assets/R8/PR_USVI/TimeSync/18_PRVI_AllPlots_TimeSync_Annualized_Table_secLC'\n",
    "\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e5d6f281-1c62-44ca-a56e-00769912a05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCMS class code, names, and colors: {'Change_class_names': ['Stable', 'Slow Loss', 'Fast Loss', 'Gain', 'Non-Processing Area Mask'], 'Change_class_palette': ['3d4551', 'f39268', 'd54309', '00a398', '1b1716'], 'Change_class_values': [1, 2, 3, 4, 5], 'Land_Cover_class_names': ['Trees', 'Tall Shrubs & Trees Mix (SEAK Only)', 'Shrubs & Trees Mix', 'Grass/Forb/Herb & Trees Mix', 'Barren & Trees Mix', 'Tall Shrubs (SEAK Only)', 'Shrubs', 'Grass/Forb/Herb & Shrubs Mix', 'Barren & Shrubs Mix', 'Grass/Forb/Herb', 'Barren & Grass/Forb/Herb Mix', 'Barren or Impervious', 'Snow or Ice', 'Water', 'Non-Processing Area Mask'], 'Land_Cover_class_palette': ['005e00', '008000', '00cc00', 'b3ff1a', '99ff99', 'b30088', 'e68a00', 'ffad33', 'ffe0b3', 'ffff00', 'aa7700', 'd3bf9b', 'ffffff', '4780f3', '1b1716'], 'Land_Cover_class_values': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 'Land_Use_class_names': ['Agriculture', 'Developed', 'Forest', 'Non-Forest Wetland', 'Other', 'Rangeland or Pasture', 'Non-Processing Area Mask'], 'Land_Use_class_palette': ['efff6b', 'ff2ff8', '1b9d0c', '97ffff', 'a1a1a1', 'c2b34a', '1b1716'], 'Land_Use_class_values': [1, 2, 3, 4, 5, 6, 7], 'study_area': 'PRUSVI'}\n"
     ]
    }
   ],
   "source": [
    "Map.proxy_url = workbench_url\n",
    "\n",
    "# First, we'll need to repeat steps from Module 5 and download our reference data to a local location\n",
    "# Bring in raw TS data\n",
    "timeSyncData = ee.FeatureCollection(timeSync_featureCollection)\n",
    "timeSync_fields = timeSyncData.first().toDictionary().keys().getInfo()\n",
    "# Now lets bring in all training data and prep it for modeling\n",
    "assets = ee.data.listAssets({'parent': export_timeSync_folder})['assets']\n",
    "\n",
    "# You may need to change the permissions for viewing model outputs in geeViz\n",
    "# Uncomment this if needed\n",
    "# for asset in assets:aml.updateACL(asset['name'],writers = [],all_users_can_read = True,readers = [])\n",
    "\n",
    "# Read in each year of extracted TimsSync data\n",
    "training_data = ee.FeatureCollection([ee.FeatureCollection(asset['name']) for asset in assets]).flatten()\n",
    "\n",
    "# Bring in existing LCMS data for the class names, numbers, and colors\n",
    "lcms_viz_dict = ee.ImageCollection(\"USFS/GTAC/LCMS/v2020-6\").first().toDictionary().getInfo()\n",
    "                                             \n",
    "print('LCMS class code, names, and colors:',lcms_viz_dict)\n",
    "\n",
    "\n",
    "# Get the field names for prediction\n",
    "# Find any field that was not in the original TimeSync data and assume that is a predictor variable\n",
    "all_fields = training_data.first().toDictionary().keys().getInfo()\n",
    "predictor_field_names = [field for field in all_fields if field not in timeSync_fields]\n",
    "\n",
    "# Filter out any non null values (any training plot with missing predictor data will cause the model to fail entirely)\n",
    "training_data = training_data.filter(ee.Filter.notNull(predictor_field_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "08213c22-8e96-4d29-9cb4-bdd60dac1c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crosswalking: Land_Cover\n",
      "Crosswalking: Land_Use\n",
      "Crosswalking: Change\n",
      "/tmp/lcms-training/local_modeling/timeSync_training_table.csv  already exists\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Now, we'll crosswalk the training fields to numeric codes\n",
    "# The TimeSync fields are a string by default\n",
    "# They must be a number for modeling\n",
    "# Set up lookup dictionaries to convert the names to numeric codes\n",
    "land_cover_name_code_dict = ee.Dictionary({'TREES':1,\n",
    "                             'TSHRUBS-TRE':2,\n",
    "                             'SHRUBS-TRE':3,\n",
    "                             'GRASS-TREE':4,\n",
    "                             'BARREN-TRE':5,\n",
    "                             'TSHRUBS':6,\n",
    "                             'SHRUBS':7,\n",
    "                             'GRASS-SHRU':8,\n",
    "                             'BARREN-SHR':9,\n",
    "                             'GRASS':10,\n",
    "                             'BARREN-GRA':11,\n",
    "                             'BARREN-IMP':12,\n",
    "                             'BARREN-IMP':12,\n",
    "                             'WATER':14\n",
    "                            })\n",
    "land_use_name_code_dict = ee.Dictionary({'Agriculture':1,\n",
    "                           'Developed':2,\n",
    "                           'Forest':3,\n",
    "                           'Non-forest Wetland':4,\n",
    "                           'Other':5,\n",
    "                           'Rangeland':6\n",
    "                          })\n",
    "\n",
    "change_code_dict = ee.Dictionary({'Debris': 3, \n",
    "                                  'Fire': 3, \n",
    "                                  'Growth/Recovery': 4, \n",
    "                                  'Harvest': 3, 'Hydrology': 3, \n",
    "                                  'Mechanical': 3, \n",
    "                                  'Other': 3, \n",
    "                                  'Spectral Decline': 2, \n",
    "                                  'Stable': 1, \n",
    "                                  'Structural Decline': 2, \n",
    "                                  'Wind/Ice': 3})\n",
    "\n",
    "reference_field_dict = {'Land_Cover':{'field':'DOM_SEC_LC','name_code_dict':land_cover_name_code_dict},\n",
    "                        'Land_Use':{'field':'DOM_LU','name_code_dict':land_use_name_code_dict},\n",
    "                        'Change':{'field':'CP','name_code_dict':change_code_dict,\n",
    "                                  'fields':['Slow Loss', 'Fast Loss', 'Gain']}\n",
    "                       }\n",
    "# Make a function that will get the code for a given name and set it\n",
    "# We could also use the remap function to accomplish this\n",
    "def set_class_code(plot,product):\n",
    "    name_fieldName = reference_field_dict[product]['field']\n",
    "    code_fieldName = ee.String(name_fieldName).cat('_Code')\n",
    "    name = ee.String(plot.get(name_fieldName))\n",
    "    code = reference_field_dict[product]['name_code_dict'].get(name)\n",
    "    plot = plot.set(code_fieldName,code)\n",
    "    return plot\n",
    "                    \n",
    "                    \n",
    "    # print(name_fieldName,code_fieldName.getInfo(),name.getInfo(),code.getInfo())\n",
    "            \n",
    "# set_class_code(training_data.first(),'Land_Cover')\n",
    "for product in list(reference_field_dict.keys()):\n",
    "    print('Crosswalking:',product)\n",
    "    training_data = training_data.map(lambda f:set_class_code(f,product))\n",
    "\n",
    "# Now will download the training table to a local location\n",
    "\n",
    "local_model_data_folder = '/tmp/lcms-training/local_modeling'\n",
    "local_training_csv = os.path.join(local_model_data_folder,'timeSync_training_table.csv')\n",
    "\n",
    "\n",
    "if not os.path.exists(local_model_data_folder):os.makedirs(local_model_data_folder)\n",
    "\n",
    "# Download the training data from a featureCollection to a local CSV\n",
    "# This function will automatically break the featureCollection into 5000 feature featureCollections\n",
    "# if it is larger than the 5000 feature limit set by GEE\n",
    "g2p.featureCollection_to_csv(training_data,local_training_csv,overwrite = False)\n",
    "\n",
    "# Once the table is store locally, read it in\n",
    "training_df = pd.read_csv(local_training_csv)\n",
    "\n",
    "training_df.describe()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2b1aff8d-b726-4fed-8cd9-d8851c947279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold Number: 1\n",
      "\n",
      "16792 4199\n",
      "16792\n",
      "\n",
      "Fold Number: 2\n",
      "\n",
      "16793 4198\n",
      "16793\n",
      "\n",
      "Fold Number: 3\n",
      "\n",
      "16793 4198\n",
      "16793\n",
      "\n",
      "Fold Number: 4\n",
      "\n",
      "16793 4198\n",
      "16793\n",
      "\n",
      "Fold Number: 5\n",
      "\n",
      "16793 4198\n",
      "16793\n"
     ]
    }
   ],
   "source": [
    "# LCMS does not have enough training samples to simply ommit 20% or so from training our final models\n",
    "# Since our assemblage process introduces differences between the model predicted class, and our sample\n",
    "# is based on a stratified random sample design, we cannot simply use the out-of-bag samples from the random forest model\n",
    "# We have to use a method that will simulate the map accuracy that can account for the likelihood of each samples inclusion\n",
    "# (strata weights), as well as also allow us to introduce any assemblage rules that are not typically part of the underlying \n",
    "# random forest model\n",
    "# \n",
    "\n",
    "KFoldInfo = {}\n",
    "# kfoldinfo_pickle_filename = pickleName+'.p'\n",
    "KFoldInfo['TrainingData'] = training_df.copy()\n",
    "\n",
    "# strata = allTrainingData[stratColumn].squeeze()\n",
    "groups = training_df['PLOTID'].squeeze()\n",
    "k = 5\n",
    "n_jobs = 4\n",
    "gkf = GroupKFold(n_splits=k)\n",
    "foldNum = 1\n",
    "seed = 999\n",
    "nTrees = 5\n",
    "# Fit and Train model\n",
    "# Set up a random forest model\n",
    "rf = RandomForestClassifier(n_estimators = nTrees, random_state=seed,oob_score=True,n_jobs = n_jobs)\n",
    "\n",
    "for train_index, test_index in gkf.split(training_df, training_df, groups):\n",
    "    KFoldInfo[str(foldNum)] = {}\n",
    "    print()\n",
    "    print('Fold Number: '+str(foldNum))\n",
    "    print()\n",
    "    print(len(train_index),len(test_index))\n",
    "    # Indices of training and test samples\n",
    "    KFoldInfo[str(foldNum)]['Indices'] = {\\\n",
    "        'Train': train_index,\n",
    "        'Test': test_index}\n",
    "\n",
    "    # Strata of training and test samples\n",
    "    # gk_strata_train, gk_strata_test = strata.iloc[train_index], strata.iloc[test_index]\n",
    "#     KFoldInfo[str(foldNum)]['Strata'] = {\\\n",
    "#         'Train': gk_strata_train,\n",
    "#         'Test': gk_strata_test}\n",
    "\n",
    "#     # Run model and predict probabilities\n",
    "#     KFoldInfo[str(foldNum)]['Probabilities'] = {}\n",
    "#     KFoldInfo[str(foldNum)]['Predictions'] = {}\n",
    "#     KFoldInfo[str(foldNum)]['Model'] = {}\n",
    "    \n",
    "    k_train,k_test = training_df.iloc[train_index], training_df.iloc[test_index]\n",
    "    print(len(k_train))\n",
    "    # for product in list(reference_field_dict.keys()):\n",
    "        # print(foldNum,product)\n",
    "        \n",
    "        # Get X and Y points for each group  \n",
    "       \n",
    "        # gkx_train, gkx_test = training_df.iloc[train_index], training_df.iloc[test_index]\n",
    "        # gky_train, gky_test = indDict[model]['y'].iloc[train_index], indDict[model]['y'].iloc[test_index]\n",
    "    foldNum+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd68ce-906c-486e-892d-d19c12f459c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another method for computing model accuracy is with cross validation\n",
    "# This method partitions the data into k parts and leaves one out for each of k iterations\n",
    "# The held out training points are then used to assess the model accuracy. All held out samples are combined to \n",
    "# get the simulated model accuracy\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(rf, X, y, cv=10,scoring = 'balanced_accuracy')\n",
    "print(\"%0.2f balanced accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
