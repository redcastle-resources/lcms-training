{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2eb2fc88-25b8-4d5a-8a2c-b8e40cbe6178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae243bdf-1298-4668-a561-3709d7a26995",
   "metadata": {
    "id": "title:generic,gcp"
   },
   "source": [
    "<img width=50px  src = 'https://apps.fs.usda.gov/lcms-viewer/images/lcms-icon.png'>\n",
    "\n",
    "# Lab 6: LCMS Map Assemblage\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/redcastle-resources/lcms-training/blob/main/6-Map_Assemblage.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/redcastle-resources/lcms-training/blob/main/6-Map_Assemblage.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://github.com/redcastle-resources/lcms-training/blob/main/6-Map_Assemblage.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4603c77e-11e2-45bc-9ddd-b75c4a170d8b",
   "metadata": {
    "id": "overview:mlops"
   },
   "source": [
    "\n",
    "## 6.0: Overview and Introduction\n",
    "\n",
    "\n",
    "This notebook teaches how to take raw model outputs and assemble final map classes\n",
    "\n",
    "\n",
    "### 6.0.1: Objective\n",
    "\n",
    "In this tutorial, you learn how to manipulate raw model output GEE image arrays to create map outputs of a single class.\n",
    "\n",
    "This tutorial uses the following Google Cloud services:\n",
    "\n",
    "- `Google Earth Engine`\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "- Looking at raw GEE image array model output assets\n",
    "- Manipulating the image arrays for a basic map assemblage\n",
    "- Performing a more complicated map assemblage that balances omission and commission for Change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4a573f-29c3-483d-9e35-f96910089b67",
   "metadata": {},
   "source": [
    "### 6.0.2: Before you begin\n",
    "\n",
    "#### If you are working in Workbench: Set your current URL under `workbench_url`\n",
    "This gives the Map Viewer a url in which to host the viewer we will be generating. \n",
    "* This will be in your URL/search bar at the top of the browser window you are currently in\n",
    "* It will look something like `https://1234567890122-dot-us-west3.notebooks.googleusercontent.com/` (See the image below)\n",
    "\n",
    "![workspace url](img/workspace-url.png)\n",
    "\n",
    "#### Set a folder to use for all exports under `export_path_root` \n",
    "* This folder should be an assets folder in an existing GEE project.\n",
    "* By default, this folder is the same as the pre-baked folder (where outputs have already been created). \n",
    "* If you would like to create your own outputs, specify a different path for `export_path_root`, but leave the `pre_baked_path_root` as it was. This way, the pre-baked outputs can be shown at the end, instead of waiting for all exports to finish.\n",
    "* It will be something like `projects/projectID/assets/newFolder`\n",
    "* This folder does not have to already exist. If it does not exist, it will be created\n",
    "\n",
    "**If you are working in Qwiklabs and wish to export:** Copy the project ID from the 'Start Lab' screen into the `projectID` field in `export_path_root`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7b2ff50-e53b-4857-989d-c2e75d203f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "workbench_url = 'https://7c39a91cfd2f6ff9-dot-us-central1.notebooks.googleusercontent.com/'\n",
    "pre_baked_path_root  = 'projects/rcr-gee/assets/lcms-training'\n",
    "export_path_root = pre_baked_path_root\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c3e1a4-9342-4137-9f03-f17c469568d5",
   "metadata": {},
   "source": [
    "#### Installation\n",
    "First, install necessary Python packages. Uncomment the first line to upgrade geeViz if necessary.\n",
    "\n",
    "Note that for this module, we're also importing many data science packages such as pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fae6857-1dfc-448b-b92f-85ec010f8460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Module imports\n",
    "#!python -m pip install geeViz --upgrade\n",
    "try:\n",
    "    import geeViz.getImagesLib as getImagesLib\n",
    "except:\n",
    "    !python -m pip install geeViz\n",
    "    import geeViz.getImagesLib as getImagesLib\n",
    "\n",
    "import geeViz.changeDetectionLib as changeDetectionLib\n",
    "import geeViz.assetManagerLib as aml\n",
    "import geeViz.taskManagerLib as tml\n",
    "import geeViz.gee2Pandas as g2p\n",
    "import inspect,operator\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd  \n",
    "# from IPython.display import IFrame,display, HTML\n",
    "ee = getImagesLib.ee\n",
    "Map = getImagesLib.Map\n",
    "\n",
    "# Can set the port used for viewing map outputs\n",
    "Map.port = 1235\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855641a3-d7c4-431b-a87f-1a8db2727fc4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Set up your work environment\n",
    "\n",
    "Create a folder in your export path where you will export the composites. In addition, create a blank image collection where your composites will live.\n",
    "\n",
    "Currently, when running within Colab or Workbench, geeView uses a different project to authenticate through, so you may need to make your asset public to view from within Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed03b3ae-31ec-4caf-9add-5d9d1eb1bec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the following sub directories:  ['lcms-training', 'lcms-training_module-6_assembledLCMSOutputs']\n",
      "Will attempt to create them if they do not exist\n",
      "projects/rcr-gee/assets/lcms-training\n",
      "Could not create:  projects/rcr-gee/assets/lcms-training\n",
      "Permission 'earthengine.assets.create' denied on resource 'projects/rcr-gee' (or it may not exist).\n",
      "Asset projects/rcr-gee/assets/lcms-training/lcms-training_module-6_assembledLCMSOutputs already exists\n",
      "Updating permissions for:  projects/rcr-gee/assets/lcms-training/lcms-training_module-6_assembledLCMSOutputs\n",
      "Could not update permissions for:  projects/rcr-gee/assets/lcms-training/lcms-training_module-6_assembledLCMSOutputs\n",
      "Asset 'projects/rcr-gee/assets/lcms-training/lcms-training_module-6_assembledLCMSOutputs' does not exist or doesn't allow this operation.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Bring in all folders/collections that are needed\n",
    "# These must already exist as they are created in previous notebooks\n",
    "export_rawLCMSOutputs_collection = f'{export_path_root}/lcms-training_module-5_rawLCMSOutputs'\n",
    "\n",
    "export_assembledLCMSOutputs_collection = f'{export_path_root}/lcms-training_module-6_assembledLCMSOutputs'\n",
    "\n",
    "\n",
    "aml.create_asset(export_assembledLCMSOutputs_collection, asset_type = ee.data.ASSET_TYPE_IMAGE_COLL)\n",
    "\n",
    "# Currently geeView within Colab uses a different project to authenticate through, so you may need to make your asset public to view from within Colab\n",
    "aml.updateACL(export_assembledLCMSOutputs_collection,writers = [],all_users_can_read = True,readers = [])\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5f9ff81-93f9-4f9e-a913-5359d56a6666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# set up map\n",
    "Map.clearMap()\n",
    "\n",
    "# reset port if necessary\n",
    "Map.port = 1235\n",
    "Map.proxy_url = workbench_url\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1a977b-79c1-4bee-895f-75b45e46de0d",
   "metadata": {},
   "source": [
    "## 6.1: Bring in Raw LCMS Outputs and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a153137b-a555-4c6c-91c3-f5cee02de653",
   "metadata": {},
   "outputs": [],
   "source": [
    "Map.clearMap()\n",
    "# Bring in raw LCMS model outputs\n",
    "raw_lcms = ee.ImageCollection(export_rawLCMSOutputs_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c2439-3b12-4893-ac7a-7224b56b62a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect raw LCMS model outputs to show that each band is the probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b33a17f-09d0-4621-b082-430af42aa0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in existing LCMS data for the class names, numbers, and colors\n",
    "lcms_viz_dict = ee.ImageCollection(\"USFS/GTAC/LCMS/v2022-8\").filter('study_area==\"PRUSVI\"').first().toDictionary().getInfo()\n",
    "# print(lcms_viz_dict)\n",
    "    \n",
    "# Get some info\n",
    "products = raw_lcms.aggregate_histogram('product').keys().getInfo()\n",
    "\n",
    "\n",
    "# Specify missing classes in PRUSVI\n",
    "# Talls Shrubs (2 and 6)  and snow/ice (13) are not present and need filled back in\n",
    "# Change and Land_Use have all values\n",
    "missing_names = {'Change':[],\n",
    "                  'Land_Cover':['Tall Shrubs & Trees Mix (SEAK Only)',\n",
    "                                'Tall Shrubs (SEAK Only)',\n",
    "                                'Snow or Ice'],\n",
    "                  'Land_Use':[]\n",
    "                 }\n",
    "def arrayToImage(img,bandNames):\n",
    "    return img.arrayProject([0])\\\n",
    "            .arrayFlatten([bandNames])\\\n",
    "            .copyProperties(img,['system:time_start'])\n",
    "\n",
    "# var c = ee.ImageCollection('projects/rcr-gee/assets/lcms-training/lcms-training_module-5_rawLCMSOutputs')\n",
    "        # .filter(ee.Filter.eq('product','Land_Cover'))\n",
    "\n",
    "# Function to add in a fill value in a 1-d image array of a given index and value\n",
    "def fillArray(img,index,fillValue=0):\n",
    "    imgLeft = img.arraySlice(0,0,index)\n",
    "    imgRight = img.arraySlice(0,index,None)\n",
    "    imgLeft = imgLeft.arrayCat(ee.Image(fillValue).toArray(),0)\n",
    "    out = imgLeft.arrayCat(imgRight,0)\n",
    "    return ee.Image(out.copyProperties(img).copyProperties(img,['system:time_start']))\n",
    "\n",
    "# Function to handle filling multiple values\n",
    "def fillArrayMulti(img,indices,fillValue):\n",
    "    for index in indices:\n",
    "        img = fillArray(img,index,fillValue)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491dd861-0cd5-45c4-b7c2-e5b1967caa90",
   "metadata": {},
   "source": [
    "## 6.2: Basic Model Assemblage: Most Confident Class\n",
    "* Get the class code of the most confident class\n",
    "* This is the most basic assemblage method and most commonly used\n",
    "* We will start with this approach and then illustrate when this simple approach may not create the best map in some instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f419047-1c4d-4fa8-8af0-e389bb0fb988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding layer: Raw LCMS Change\n",
      "Adding layer: Most Probable LCMS Change\n",
      "Adding layer: Raw LCMS Land Cover\n",
      "Adding layer: Most Probable LCMS Land Cover\n",
      "Adding layer: Raw LCMS Land Use\n",
      "Adding layer: Most Probable LCMS Land Use\n",
      "Starting webmap\n",
      "Using default refresh token for geeView: /home/jupyter/.config/earthengine/credentials\n",
      "Starting local web server at: http://localhost:1235/geeView/\n",
      "HTTP server command: \"/opt/conda/bin/python\" -m http.server  1235\n",
      "Done\n",
      "cwd /home/jupyter/lcms-training\n",
      "Workbench Proxy URL: https://7c39a91cfd2f6ff9-dot-us-central1.notebooks.googleusercontent.com/proxy/1235/geeView/?accessToken=None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"525px\"\n",
       "            src=\"https://7c39a91cfd2f6ff9-dot-us-central1.notebooks.googleusercontent.com/proxy/1235/geeView/?accessToken=None\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f4fd92e7c40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/Sep/2023 22:52:06] \"GET /geeView/?accessToken=None HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2023 22:52:07] \"GET /geeView/js/runGeeViz.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2023 22:52:07] \"GET /geeView/css/style.min.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2023 22:52:07] \"GET /geeView/js/gena-gee-palettes.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2023 22:52:07] \"GET /geeView/js/load.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2023 22:52:07] \"GET /geeView/js/lcms-viewer.min.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2023 22:52:07] \"GET /geeView/images/GEE_logo_transparent.png HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2023 22:52:07] \"GET /geeView/images/layer_icon.png HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2023 22:52:07] \"GET /geeView/images/GEE.png HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2023 22:52:07] \"GET /geeView/images/usfslogo.png HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2023 22:52:07] \"GET /geeView/images/menu-hamburger_ffffff.svg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2023 22:52:07] \"GET /geeView/images/usdalogo.png HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2023 22:52:07] \"GET /geeView/images/logos_usda-fs.svg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Sep/2023 22:52:16] \"GET /geeView/images/cumulative_icon.png HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Get the class code of the most confident class\n",
    "# This is the most basic assemblage method and most commonly used\n",
    "# We will start with this approach and then illustrate when this simple approach may not \n",
    "# create the best map in some instances\n",
    "def getMostProbableClass(raw_lcms_product_yr,product):\n",
    "    # Pull the index of the most probable value\n",
    "    # Since 0 is not used for LCMS outputs, add 1\n",
    "    max_prob_class = raw_lcms_product_yr.arrayArgmax().arrayGet(0).add(1).byte().rename([product])\n",
    "    max_prob_class = ee.Image(max_prob_class)\n",
    "\n",
    "    null_code = lcms_viz_dict[f'{product}_class_values'][-1]\n",
    "    max_prob_class = max_prob_class.unmask(null_code)\n",
    "    return max_prob_class.copyProperties(raw_lcms_product_yr,['system:time_start'])\n",
    "\n",
    "# Iterate across each product and assemble the most probable class collection from the raw\n",
    "for product in products:\n",
    "    # Pull the class names\n",
    "    class_names = lcms_viz_dict[f'{product}_class_names'][:-1]\n",
    "   \n",
    "    product_title = product.replace('_',' ')\n",
    "    \n",
    "    # Filter to only include the product of interest\n",
    "    raw_lcms_product = raw_lcms.filter(ee.Filter.eq('product',product))\n",
    "    \n",
    "    # Fill in any missing values\n",
    "    missing_names_product = missing_names[product]\n",
    "    missing_indices_product = [lcms_viz_dict[f'{product}_class_names'].index(missing_name_product) for missing_name_product in missing_names_product]\n",
    "    \n",
    "    if len(missing_names_product) > 0:\n",
    "        raw_lcms_product = raw_lcms_product.map(lambda img: fillArrayMulti(img,missing_indices_product,0))\n",
    "    \n",
    "    # Find the max probability class\n",
    "    maxProb_lcms_product = raw_lcms_product.map(lambda raw_lcms_product_yr:getMostProbableClass(raw_lcms_product_yr,product).set(lcms_viz_dict))\n",
    "    \n",
    "    # Convert raw model probabilities to bands for exploration\n",
    "    raw_lcms_product = raw_lcms_product.map(lambda img:arrayToImage(img,class_names))\n",
    "    \n",
    "    # Add the raw model probabilities to query\n",
    "    Map.addTimeLapse(raw_lcms_product,{'addToLegend':False},f'Raw LCMS {product_title}')\n",
    "    \n",
    "    # Add the assembed final class maps\n",
    "    Map.addTimeLapse(maxProb_lcms_product,{'autoViz':True},f'Most Probable LCMS {product_title}')\n",
    "Map.turnOnInspector()\n",
    "Map.view()\n",
    "# Take note that the Raw LCMS Change probabilities generally have stable as the most probable\n",
    "# We will need a different assemblage method for change\n",
    "# print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37805dbb-7b05-4b0b-8f03-adc4cf388893",
   "metadata": {},
   "source": [
    "## 6.3 Compute Change Thresholds\n",
    "\n",
    "* Change is generally a rare class\n",
    "* As we noted earlier, uur training data have far more stable plots than change plots\n",
    "* As a result, most of the time, our models are not very confident of change\n",
    "* We do not use the class the model was most confident of for change classification\n",
    "* Instead, we take any of the 3 change classes that are above a threshold that balances omission and commission error and then take the most confident classs (should more than one be above their respective thresholds)\n",
    "* The next blocks compute the thresholds that balance omission and commission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87b72d9f-5c0d-4bf0-aa92-80f9baa91db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify how many trees to include in the RF model\n",
    "nTrees=150\n",
    "\n",
    "# Select which product (we only use this method for Change)\n",
    "product_name = 'Change'\n",
    "\n",
    "# load model options df\n",
    "\n",
    "# First set up a the predictor and reference field names\n",
    "model_options_df = model_options_df[model_options_df['Model Name'] == 'Non-correlated Predictors Top 30']\n",
    "\n",
    "# Pull the predictor variables from the prior exercise\n",
    "predictor_variable_names = model_options_df[model_options_df['Product Name'] == product_name]['Var Imp'].values[0]\n",
    "\n",
    "code_field_name = reference_field_dict[product_name]['field']+'_Code'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3701d064-7a3c-4bec-8b66-b3796ee8148b",
   "metadata": {},
   "source": [
    "### 6.3.1: Set up Random Forest Model for thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "033c6aba-b3f3-4376-a61b-0cf7a329eee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting models for thresholding\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Split the training data as we did before into dependent (y) and independent (X) variables\n",
    "X = training_df[predictor_variable_names]\n",
    "y = training_df[code_field_name]\n",
    "groups = training_df['PLOTID']\n",
    "# Split them into a test and train set for further model evaluation\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Ensure all plots are grouped into either test or split so temporally auto-correlated \n",
    "# plots do not get into the training set and inflate accuracy\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=0.8)\n",
    "for i, (train_index, test_index) in enumerate(gss.split(X, y, groups)):\n",
    "    train_index = train_index\n",
    "    test_index = test_index\n",
    "\n",
    "X_train, X_test, y_train, y_test = X.iloc[train_index],X.iloc[test_index],y.iloc[train_index],y.iloc[test_index]\n",
    "\n",
    "# Set up a random forest model\n",
    "print('Fitting models for thresholding')\n",
    "rf_all = RandomForestClassifier(n_estimators = nTrees, random_state=seed,oob_score=True,)\n",
    "rf_holdout = RandomForestClassifier(n_estimators = nTrees, random_state=seed,oob_score=True,)\n",
    "\n",
    "# Fit using all training as well as the holdout\n",
    "rf_all = rf_all.fit(X,y)\n",
    "rf_holdout = rf_holdout.fit(X_train,y_train)\n",
    "\n",
    "# Apply the model and get the proportion of votes for each class\n",
    "rf_all_probs = rf_all.predict_proba(X)\n",
    "rf_holdout_probs = rf_holdout.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2bbc52-81f0-4807-b22b-3f7e75eb0e35",
   "metadata": {},
   "source": [
    "### 6.3.2: Compute proportion of votes that balance omission and comission\n",
    "* Next we'll compute the proportion of votes that balances omission and commission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf29b9e-e2ba-4070-a5e6-221c95e0cc3f",
   "metadata": {},
   "source": [
    "\n",
    "* While this assemblage method works well, you can introduce various rules to tailor the final map product to different audiences\n",
    "* In the case of LCMS, there is a focus on forest applications\n",
    "* We know that our models are generally not very confident about classifying change largely due to the limited number of training samples that experience change\n",
    "* We also know our land use classes are not mutually exclusive (e.g. non-forest wetlands can potentially occur in any land use)\n",
    "* Therefore we have a lot of confusion in our land use outputs\n",
    "\n",
    "* Since a pixel may have probabilities above the threshold of more than one class, we choose the class with the model confidence that is the highest probability that is also above its respective threshold. \n",
    "* e.g. if the fast loss probability is 0.5 and the slow loss probability is 0.35, the pixel will be assigned fast loss\n",
    "* We will not include stable since stable will be any pixel that is not already assigned to one of the 3 change classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b08aaf53-e18e-48c7-ab67-f895a4d1732f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m change_class_codes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStable\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSlow Loss\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m2\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFast Loss\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m3\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGain\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m4\u001b[39m}\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Make a function that will take a list of binary reference and probablity (0-1 float) \u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# predicted values and find the optimal threshold to balance omission and commission\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetBalancedThreshold\u001b[39m(y_ref_binary,y_pred_probs,title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOmission-Commission Error\u001b[39m\u001b[38;5;124m'\u001b[39m,thresholds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0.005\u001b[39m))):\n\u001b[1;32m     10\u001b[0m     omission \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     11\u001b[0m     commission \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Next we'll compute the proportion of votes that balances omission and commission\n",
    "\n",
    "# Specify individual class names and codes for change\n",
    "change_class_codes = {'Stable':1,'Slow Loss':2,'Fast Loss':3,'Gain':4}\n",
    "\n",
    "# Make a function that will take a list of binary reference and probablity (0-1 float) \n",
    "# predicted values and find the optimal threshold to balance omission and commission\n",
    "def getBalancedThreshold(y_ref_binary,y_pred_probs,title='Omission-Commission Error',thresholds = list(np.arange(0,1,0.005))):\n",
    "    \n",
    "    omission = []\n",
    "    commission = []\n",
    "    \n",
    "    # Iterate across each threshold and compute the omission and commision error rates\n",
    "    for threshold in thresholds:\n",
    "        \n",
    "        y_pred_binary = np.where(y_pred_probs>threshold, 1, 0)\n",
    "        fp = (y_pred_binary == 1) & (y_ref_binary == 0) \n",
    "        pred_positive = y_pred_binary == 1\n",
    "        ref_positive = y_ref_binary == 1\n",
    "        ref_negative = y_ref_binary == 0\n",
    "        fn = (y_pred_binary == 0) & (y_ref_binary == 1) \n",
    "        tp = (y_pred_binary == 1) & (y_ref_binary == 1) \n",
    "        commission.append(sum(fp)/sum(pred_positive))\n",
    "        omission.append(sum(fn)/sum(ref_positive))\n",
    "    \n",
    "    # Find the threshold that corresponds to the smallest difference between omission and commission\n",
    "    diff = np.abs(np.array(omission)-np.array(commission))\n",
    "    diff = np.stack((thresholds,diff,omission,commission),1)\n",
    "    diff = diff[diff[:, 1].argsort()]\n",
    "    crossover = diff[0]\n",
    "    optimal_thresh = crossover[0]\n",
    "    \n",
    "    # Plot the curves\n",
    "    plt.plot(thresholds, commission,label='Commission')\n",
    "    plt.plot(thresholds,omission, '-.',label='Omission')\n",
    "    plt.axvline(x = optimal_thresh, color = 'g', label = f'Optimal Threshold ({optimal_thresh} {crossover[2]} {crossover[3]})')\n",
    "    plt.xlabel(\"Proportion RF Model Votes\")\n",
    "    plt.ylabel(\"Error Rate\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return optimal_thresh\n",
    "\n",
    "# Iterate across each class and find the optimal threshold\n",
    "out_threshold_dict = {}\n",
    "for change_class,change_code in list(change_class_codes.items()):\n",
    "    print(change_class,change_code)\n",
    "    y_pred_prob_rf_all =rf_all_probs[:,change_code-1]\n",
    "    y_pred_prob_rf_holdout =rf_holdout_probs[:,change_code-1]\n",
    "    \n",
    "    y_ref_binary = np.where(y==change_code, 1, 0)\n",
    "    y_test_binary = np.where(y_test==change_code,1,0)\n",
    "    rf_all_thresh = getBalancedThreshold(y_ref_binary,y_pred_prob_rf_all,f'All Training Plots - {change_class}')\n",
    "    rf_holdout_thresh = getBalancedThreshold(y_test_binary,y_pred_prob_rf_holdout,f'Held Out Training Plots - {change_class}')\n",
    "    out_threshold_dict[change_class] = rf_holdout_thresh\n",
    "\n",
    "print(out_threshold_dict)\n",
    "\n",
    "# Save table for use \n",
    "model_options_csv_filename = os.path.join(local_model_data_folder,'LCMS_change_thresholds.csv')\n",
    "o = open(model_options_csv_filename,'w')\n",
    "o.write(json.dumps(out_threshold_dict))\n",
    "o.close()\n",
    "\n",
    "o = open(model_options_csv_filename,'r')\n",
    "threshs = json.load(o)\n",
    "o.close()\n",
    "\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d602d9d-1f92-4a74-a576-94349354c78b",
   "metadata": {},
   "source": [
    "* Notice if we don't use a holdout, the threshold always hovers near 0.5\n",
    "* This is wrong since the model contains the data being used to derive the threshold\n",
    "* Also notice the slow loss threshold is near zero with an error rate near 1. Recall we have very few slow loss samples. This indicates our models are unlikely to be able to predict slow loss at all.\n",
    "* Note that both fast loss and gain have thresholds far below 0.5 and error rates around 0.7 or so. This indicates our models are rarely confident of classifying these classes, and the omission and commission error rates are high. Simply put, TimeSync is much more sensitive to detecting change than any model is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55739ba8-5486-4fdb-84aa-1c88c8d1c876",
   "metadata": {},
   "source": [
    "## 6.3.3: Final Change Layer Assemblage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1fe9433-1971-499a-be67-e00cb484332d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding layer: Assembled LCMS Change\n",
      "Starting webmap\n",
      "Using default refresh token for geeView: /home/jupyter/.config/earthengine/credentials\n",
      "Local web server at: http://localhost:1235/geeView/ already serving.\n",
      "cwd /home/jupyter/lcms-training\n",
      "Workbench Proxy URL: https://7c39a91cfd2f6ff9-dot-us-central1.notebooks.googleusercontent.com/proxy/1235/geeView/?accessToken=None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"525px\"\n",
       "            src=\"https://7c39a91cfd2f6ff9-dot-us-central1.notebooks.googleusercontent.com/proxy/1235/geeView/?accessToken=None\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f4fd91379d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/Sep/2023 22:56:26] \"GET /geeView/js/runGeeViz.js HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Map.clearMap()\n",
    "# For assembling change, we choose thresholds that balance omission and commission\n",
    "# These were computed in module 5.1\n",
    "change_thresholds = { 'Slow Loss': 0.29, 'Fast Loss': 0.28, 'Gain': 0.36}\n",
    "\n",
    "\n",
    "\n",
    "product = 'Change'\n",
    "\n",
    "# Pull the class names\n",
    "class_names = lcms_viz_dict[f'{product}_class_names']\n",
    "class_codes = lcms_viz_dict[f'{product}_class_values']\n",
    "class_dict = dict(zip(class_names,class_codes))\n",
    "\n",
    "# Pull the codes in the correct order\n",
    "class_order_codes = [class_dict[cl] for cl in list(change_thresholds.keys())]\n",
    "\n",
    "# Filter to only include the product of interest\n",
    "raw_lcms_product = raw_lcms.filter(ee.Filter.eq('product',product))\n",
    "    \n",
    "# Function to assemble change for a given year\n",
    "# Uses a specified set of bands and thresholds in order to find the highest probability class above its threshold\n",
    "# It then fills in the stable value as any remaining non null value\n",
    "# Nulls are then recoded to the non processing code\n",
    "def assembleChange(img,product):\n",
    "    # Convert array to multi-band image\n",
    "    img = ee.Image(arrayToImage(img,lcms_viz_dict[f'{product}_class_names'][:-1]))\n",
    "    \n",
    "    # Select only the bands we'd like to assemble\n",
    "    img = img.select(list(change_thresholds.keys()))\n",
    "    \n",
    "    # Find the most confident class\n",
    "    maxConf = img.reduce(ee.Reducer.max())\n",
    "    \n",
    "    # Find pixels that are the most confident and above the threshold\n",
    "    maxConfMask = img.eq(maxConf).And(img.gte(list(change_thresholds.values()))).selfMask()\n",
    "    \n",
    "    # Get class code for any pixel that is above its threshold for the most confident class\n",
    "    maxClass = ee.Image(class_order_codes).updateMask(maxConfMask).reduce(ee.Reducer.first())\n",
    "    \n",
    "    # Fill stable back in\n",
    "    maxClass = maxClass.unmask(1)\n",
    "    \n",
    "    # Burn in non processing where the input was null\n",
    "    maxClass = maxClass.where(img.mask().reduce(ee.Reducer.min()).Not(),class_codes[-1])\n",
    "    \n",
    "    return maxClass.rename([product]).copyProperties(img).copyProperties(img,['system:time_start'])\n",
    "\n",
    "# Iterate across the change probabilities and assemble final change class\n",
    "assembledChange = raw_lcms_product.map(lambda img:assembleChange(img,product).set(lcms_viz_dict))\n",
    "\n",
    "# Explore it on the map\n",
    "Map.addTimeLapse(assembledChange,{'autoViz':True},'Assembled LCMS Change')\n",
    "\n",
    "Map.turnOnInspector()\n",
    "Map.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b62d391-f035-4741-9594-f6a24866c32b",
   "metadata": {},
   "source": [
    "#### Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51740632-06c2-4acc-ace4-9c36542efee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding layer: Most Recent Year of Fast Loss\n",
      "Starting webmap\n",
      "Using default refresh token for geeView: /home/jupyter/.config/earthengine/credentials\n",
      "Local web server at: http://localhost:1235/geeView/ already serving.\n",
      "cwd /home/jupyter/lcms-training\n",
      "Workbench Proxy URL: https://7c39a91cfd2f6ff9-dot-us-central1.notebooks.googleusercontent.com/proxy/1235/geeView/?accessToken=None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"525px\"\n",
       "            src=\"https://7c39a91cfd2f6ff9-dot-us-central1.notebooks.googleusercontent.com/proxy/1235/geeView/?accessToken=None\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f4fd9110cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Change', 'year']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/Sep/2023 23:10:44] \"GET /geeView/js/runGeeViz.js HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "Map.clearMap()\n",
    "# Viewing change outputs can be easier as a composite that shows the most recent year of a single change type\n",
    "# This example will show the most recent year of fast loss\n",
    "\n",
    "# First, add a year constant band\n",
    "assembledChange = assembledChange.map(getImagesLib.addYearBand)\n",
    "\n",
    "# Then mask where change equals fast loss (3)\n",
    "fastLoss = assembledChange.map(lambda img: img.updateMask(img.select([0]).eq(3)))\n",
    "\n",
    "# Find the most recent year\n",
    "mostRecentFastLoss = fastLoss.max().select(['year'])\n",
    "Map.addLayer(mostRecentFastLoss,{'min':1985,'max':2022,'palette':changeDetectionLib.lossYearPalette},'Most Recent Year of Fast Loss')\n",
    "\n",
    "Map.turnOnInspector()\n",
    "Map.view()\n",
    "print(assembledChange.first().bandNames().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be599c0-0790-4ca7-bb88-4501542720a1",
   "metadata": {},
   "source": [
    "## 6.4: Export Assembled assets\n",
    "\n",
    "* Now lets export assembled assets\n",
    "\n",
    "* OPTIONAL!!!!\n",
    "* Optionally, we can export using the tile grid approach\n",
    "* For PRUSVI, LCMS does not need to export using this approach, but this is how you would set it up\n",
    "* First, we'll set up the study area and a tile to export across"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e65ba06-c1a4-46a3-ab48-c6d6659ea692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding layer: Tile Grid 240000m\n",
      "Starting webmap\n",
      "Using default refresh token for geeView: /home/jupyter/.config/earthengine/credentials\n",
      "Local web server at: http://localhost:1235/geeView/ already serving.\n",
      "cwd /home/jupyter/lcms-training\n",
      "Workbench Proxy URL: https://7c39a91cfd2f6ff9-dot-us-central1.notebooks.googleusercontent.com/proxy/1235/geeView/?accessToken=None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"525px\"\n",
       "            src=\"https://7c39a91cfd2f6ff9-dot-us-central1.notebooks.googleusercontent.com/proxy/1235/geeView/?accessToken=None\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f4fda3971c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/Sep/2023 23:10:58] \"GET /geeView/js/runGeeViz.js HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "Map.clearMap()\n",
    "# Now lets export assembled assets\n",
    "\n",
    "# OPTIONAL!!!!\n",
    "# Optionally, we can export using the tile grid approach\n",
    "# For PRUSVI, LCMS does not need to export using this approach, but this is how you would set it up\n",
    "# First, we'll set up the study area and a tile to export across\n",
    "\n",
    "studyArea = ee.FeatureCollection('projects/lcms-292214/assets/R8/PR_USVI/Ancillary/prusvi_boundary')\n",
    "\n",
    "# Set the size (in meters) of the tiles\n",
    "# We can likely use a large tile for this step\n",
    "# If exports fail, reducing the tileSize is likely to help\n",
    "tileSize = 240000\n",
    "\n",
    "\n",
    "# Set the projection\n",
    "crs = getImagesLib.common_projections['NLCD_CONUS']['crs']\n",
    "transform  = getImagesLib.common_projections['NLCD_CONUS']['transform']\n",
    "scale = None\n",
    "projection = ee.Projection(crs,transform)\n",
    "\n",
    "\n",
    "# Get the grid\n",
    "grid = studyArea.geometry().coveringGrid(projection.atScale(tileSize))\n",
    "Map.addLayer(grid,{},'Tile Grid {}m'.format(tileSize))\n",
    "\n",
    "Map.centerObject(grid)\n",
    "Map.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51edfcba-8f75-4521-9c90-3834aa7a9bab",
   "metadata": {},
   "source": [
    "* Iterate across each year and assemble full stack output\n",
    "* [Example of fully assembed bands](https://developers.google.com/earth-engine/datasets/catalog/USFS_GTAC_LCMS_v2022-8#bands)\n",
    "* We will not be producing the qa-bits bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6782ae1f-f343-4629-be94-2ddca20dd75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting: LCMS_PRUSVI_v2022-Training_1985\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_1986\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_1987\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_1988\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_1989\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_1990\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_1991\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_1992\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_1993\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_1994\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_1995\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_1996\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_1997\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_1998\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_1999\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2000\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2001\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2002\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2003\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2004\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2005\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2006\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2007\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2008\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2009\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2010\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2011\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2012\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2013\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2014\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2015\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2016\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2017\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2018\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2019\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2020\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2021\n",
      "Exporting: LCMS_PRUSVI_v2022-Training_2022\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Iterate across each year, assemble full stack output \n",
    "# products = ['Land_Cover','Land_Use']\n",
    "Map.clearMap()\n",
    "\n",
    "# Provide a study area name and version\n",
    "study_area_name = 'PRUSVI'\n",
    "version = '2022-Training'\n",
    "\n",
    "# Set up years to apply models across\n",
    "apply_years = list(range(1985,2022+1))\n",
    "\n",
    "\n",
    "# This will be populated on the first iteration\n",
    "pyramidingPolicy = None\n",
    "\n",
    "\n",
    "for apply_year in apply_years:\n",
    "    assembled_list = []\n",
    "    probability_list = []\n",
    "    for product in products:\n",
    "        # Pull the class names\n",
    "        class_names = lcms_viz_dict[f'{product}_class_names'][:-1]\n",
    "        \n",
    "        # Get rid of missing class names\n",
    "        class_names = [nm for nm in class_names if nm not in missing_names[product]]\n",
    "        \n",
    "        # Get rid of any characters that aren't allowed\n",
    "        class_names = [nm.replace(' ','-').replace('/','-').replace('&','and') for nm in class_names]\n",
    "        \n",
    "        probability_names = [f'{product}_Raw_Probability_{class_name}' for class_name in class_names]\n",
    "        \n",
    "        product_title = product.replace('_',' ')\n",
    "\n",
    "        # Filter to only include the product of interest\n",
    "        raw_lcms_product_yr = raw_lcms\\\n",
    "                            .filter(ee.Filter.calendarRange(apply_year,apply_year,'year'))\\\n",
    "                            .filter(ee.Filter.eq('product',product)).first()\n",
    "        \n",
    "        if product in ['Land_Cover','Land_Use']:\n",
    "            # Find the max probability class\n",
    "            maxProb_lcms_product_yr = getMostProbableClass(raw_lcms_product_yr,product)\n",
    "            assembled_list.append(maxProb_lcms_product_yr)\n",
    "        \n",
    "        elif product == 'Change':\n",
    "            change_lcms_product_yr = assembleChange(raw_lcms_product_yr,product)\n",
    "            assembled_list.append(change_lcms_product_yr)\n",
    "            \n",
    "        # Convert raw model probabilities to bands for exploration\n",
    "        prob_lcms_product_yr = arrayToImage(raw_lcms_product_yr,probability_names)\n",
    "        probability_list.append(prob_lcms_product_yr)\n",
    "        \n",
    "    final_stack = ee.Image(ee.Image.cat([ee.Image.cat(assembled_list).byte(),ee.Image.cat(probability_list).multiply(100)]).byte()\\\n",
    "                    .copyProperties(raw_lcms_product_yr,['study_area','year']))\n",
    "\n",
    "    exportName = f'LCMS_{study_area_name}_v{version}_{apply_year}'\n",
    "    exportPath = f'{export_assembledLCMSOutputs_collection}/{exportName}'\n",
    "\n",
    "    # Set up a pyramiding object for each band\n",
    "    # Final output bands are thematic and need a mode resampling method\n",
    "    # Probability bands are continuous, so mean is appropriate\n",
    "    if pyramidingPolicy == None:\n",
    "        bns = final_stack.bandNames().getInfo()\n",
    "        pyramidingPolicy = {}\n",
    "        for bn in bns:\n",
    "            if bn.find('_Probability_') == -1:\n",
    "                pyramidingPolicy[bn] = 'mode'\n",
    "            else:\n",
    "                pyramidingPolicy[bn] = 'mean'\n",
    "   \n",
    "    getImagesLib.exportToAssetWrapper(final_stack,exportName,exportPath,pyramidingPolicy,studyArea,scale,crs,transform,overwrite=True)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34d3be9-ad5f-452c-ad0a-30bb6fbead40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 tasks ready 2023-08-22 02:57:57\n",
      "4 tasks running 2023-08-22 02:57:57\n",
      "Running names:\n",
      "['LCMS_PRUSVI_v2022-Training_2001', '0:00:44']\n",
      "['LCMS_PRUSVI_v2022-Training_2000', '0:05:39']\n",
      "['LCMS_PRUSVI_v2022-Training_1999', '0:09:12']\n",
      "['LCMS_PRUSVI_v2022-Training_1997', '0:12:41']\n",
      "\n",
      "\n",
      "21 tasks ready 2023-08-22 02:58:02\n",
      "4 tasks running 2023-08-22 02:58:02\n",
      "Running names:\n",
      "['LCMS_PRUSVI_v2022-Training_2001', '0:00:49']\n",
      "['LCMS_PRUSVI_v2022-Training_2000', '0:05:44']\n",
      "['LCMS_PRUSVI_v2022-Training_1999', '0:09:17']\n",
      "['LCMS_PRUSVI_v2022-Training_1997', '0:12:47']\n",
      "\n",
      "\n",
      "Serving HTTP on 0.0.0.0 port 4321 (http://0.0.0.0:4321/) ...\n",
      "\n",
      "Keyboard interrupt received, exiting.\n"
     ]
    }
   ],
   "source": [
    "# Can track tasks here or at https://code.earthengine.google.com/tasks\n",
    "# If you'd like to track the tasks, use this:\n",
    "tml.trackTasks2()\n",
    "\n",
    "# If you want to cancel all running tasks, you can use this function\n",
    "# tml.batchCancel()\n",
    "\n",
    "# If you want to empty the collection of all images\n",
    "# aml.batchDelete(export_rawLCMSOutputs_collection, type = 'imageCollection')\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f146769-6d26-4479-9f90-f98b5a6b6250",
   "metadata": {},
   "source": [
    "### Inspect final outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc243533-d2b8-41cd-b85e-6271aa3779c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding layer: Full Stack Output\n",
      "Adding layer: LCMS Change\n",
      "Adding layer: LCMS Land_Cover\n",
      "Adding layer: LCMS Land_Use\n",
      "Starting webmap\n",
      "Using default refresh token for geeView: /home/jupyter/.config/earthengine/credentials\n",
      "Local web server at: http://localhost:1235/geeView/ already serving.\n",
      "cwd /home/jupyter/lcms-training\n",
      "Workbench Proxy URL: https://53c21733d8125e22-dot-us-west3.notebooks.googleusercontent.com/proxy/1235/geeView/?accessToken=None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"525px\"\n",
       "            src=\"https://53c21733d8125e22-dot-us-west3.notebooks.googleusercontent.com/proxy/1235/geeView/?accessToken=None\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f04910ff1c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [22/Aug/2023 03:48:56] \"GET /geeView/js/runGeeViz.js HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# View final outputs\n",
    "Map.clearMap()\n",
    "lcms = ee.ImageCollection(export_assembledLCMSOutputs_collection)\n",
    "\n",
    "Map.addLayer(lcms,{'opacity':0},'Full Stack Output')\n",
    "lcms = lcms.map(lambda img:img.set(lcms_viz_dict))\n",
    "for product in products:Map.addTimeLapse(lcms.select([product]),{'autoViz':True},f'LCMS {product}')\n",
    "\n",
    "Map.turnOnInspector()\n",
    "Map.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20c5ec5-2c97-4224-88e3-4f1c180ef4fb",
   "metadata": {},
   "source": [
    "## Lab 6 challenge:\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7a0dac-c6c3-4934-8fe4-d93e894bf653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert challenge code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6521c5-e02f-45fe-b3a7-29c4dd44b9e4",
   "metadata": {},
   "source": [
    "## Done with Module 6"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
